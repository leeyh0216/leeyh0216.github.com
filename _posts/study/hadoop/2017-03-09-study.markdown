---
layout: post
title:  "[Study] 2017-03-09 Study"
date:   2017-03-08 20:38:00 +0900
author: leeyh0216
categories: hadoop study
---

> 이 문서는 2017/03/09 Hadoop Study에 사용하기 위해 작성되었습니다.

### 2017/03/07 제시 의견

- 데이터 직렬화를 좀 더 조사해보기
- 하둡 코드를 실제로 확인해보기

#### 데이터 직렬화

- 개념
  
  컴퓨터 과학에서 데이터 직렬화는 메모리 버퍼, 파일 혹은 네트워크를 통해서 전송되고 저장하는 데이터를 이용할 수 있는 상태로 재 구성하는 것을 의미한다.
  예를 들어 네트워크를 통해 자바 객체를 전송하고자 하면, 바이트 형태로 만들어야 하는데 이런 과정을 직렬화라고 한다.
  
  데이터를 직렬화 하고 역직렬화 하려면 데이터 포맷을 알고 있어야 하며 데이터 포맷에는 대표적으로 XML, JSON, YAML 등이 존재한다.

- 데이터 직렬화 포맷

  일반적으로 JSON, XML, YAML을 많이 사용하지만(프로그래밍 언어에 종속적이지 않음), 일반적으로 직렬화/역직렬화 하는 속도가 느리다.
  이러한 이유 때문에 Google 에서는 Protocol Buffers, Facebook에서는 Thrift(현재는 Apache Top Project)를 내놓았다.

- Google Protocol Buffers
  
  Google에서 내놓은 직렬화/역직렬화 라이브러리이다. 프로그래밍 언어에 종속적이지 않으며 매우 빠르고 쉽게 사용할 수 있다고 나와 있다.
  현재 지원하는 언어는 Java, c++, Python, Go, JavaNano, Ruby, C# 등이 있다.
  
  메시지를 정의한 후 언어에 맞게 컴파일 하면, 해당 언어의 Class로 변환되며, Builder와 Parser를 이용하여 직렬화/역직렬화를 할 수 있다.

- 메시지 정의  
{% highlight java %}
message Person {
  required string name = 1;
  required int32 id = 2;
  optional string email = 3;
}
{% endhighlight %}
- 메시지 생성
{% highlight java %}
Person john = Person.newBuilder()
    .setId(1234)
    .setName("John Doe")
    .setEmail("jdoe@example.com")
    .build();
output = new FileOutputStream(args[0]);
john.writeTo(output);
{% endhighlight %}

- 메시지 파싱
{% highlight java %}
Person john;
fstream input(argv[1],
    ios::in | ios::binary);
john.ParseFromIstream(&input);
id = john.id();
name = john.name();
email = john.email();
{% endhighlight %}

  Protocol Buffers 는 아무래도 동일한 데이터를 네트워크를 통해 전송하거나, 퍼포먼스에 영향이 큰 작업을 할 때 사용할 수 있을 듯 하다.

### Hadoop 소스 분석하기

Hadoop 소스를 분석하기 위해서 github.io의 Hadoop Repository의 Branch-2.6.3을 fork하여 가져왔다.

처음 분석했던 소스는 [hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java](https://github.com/leeyh0216/hadoop/blob/branch-2.6.3/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java) 이다.

네임노드 클래스의 정의에는 다음과 같이 역할이 적혀 있다.

>  네임노드는 Directory Namespace Manager와 Hadoop DFS를 위한 inode table을 제공합니다. DFS 개발환경에서는 단일 Namenode가 동작합니다.(장애 복구/백업용 NameNode나 Federated NameNode가 존재하지 않는 경우)
  네임노드는 다음 두 역할을 수행합니다.
  - Filename에서 BlockSequence로의 변환(namespace) : 디스크에 저장되며 매우 중요한 작업입니다.
  - Block에서 MachineList로의 변환(inode) : 네임 노드가 시작될 때마다 재구성됩니다.

> 네임 노드는 위 두 작업을 네임노드 서버 라는 이름으로 제공합니다.
  FSNamesystem 클래스는 파일시스템 관리를 수행합니다. NameNode 클래스의 주요 업무는 외부에 IPC와 Http 서버를 노출하는 것입니다.

네임노드를 구성하기 위한 속성들은 NAMENODE_SPECIFIC_KEYS 라는 String Array에 정의되어 있었다(hdfs-site.xml에 정의하는 값).
2.7.3버전에서의 Default Port는 8020이었으며, 프로세스의 중복 실행을 막기 위해서 AtomicBoolean 변수를 사용한다.
관리 서버는 HttpServer(NameNodeHttpServer 클래스), 실제 작업 서버는 RpcServer(NameNodeRpcServer)를 사용한다.

main 함수는 매우 짧다. NameNode 클래스 안의 NameNode 객체(자기 자신을 객체로 가지고 있음)을 초기화시키고 시작시키는 구문인데, NameNode를 초기화 시킬 때 바로 생성자를 호출하는 것이 아닌 static 함수를 호출하여 생성한다. 시작 속성이 다르고, 생성자가 길어지는 것을 막기 위해서 createNameNode 라는 이름의 static 함수에서 switch 문을 이용하여 분기하여 생성한다.

그 후 RpcServer Thread 를 join시킨 후 초기화가 종료된다.

제일 중요한 FileSystem 객체는 특이하게 HAContext 초기화 구문에서 시작된다.

03/08일 해당 부분까지 리뷰 후 다음 시간에 FileSystem 객체에 대해서 다뤄 보아야 할 것 같다.
