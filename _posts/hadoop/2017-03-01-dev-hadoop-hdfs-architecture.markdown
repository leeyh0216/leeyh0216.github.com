---
layout: post
title:  "[Hadoop] HDFS Architecture"
date:   2017-03-02 02:30:00 +0900
author: leeyh0216
categories: hadoop dev
---

### HDFS
HDFS는 수십 테라바이트 또는 페타바이트 이상의 파일을 분산된 서버에 저장하고, 많은 클라이언트가 저장된 데이터를 빠르게 처리할 수 있게 설계된 파일 시스템이다.

단, 기존의 NAS 등의 공유 스토리지와는 다르게 작은 파일이 아닌 큰 파일 위주로 관리되고, 처리 시간이 ms 단위가 아닌 sec 단위이므로, 일반 웹 서비스 등에는 적합하지 않다.

HDFS와 기존 대용량 파일 시스템의 가장 큰 차이는 저사양 서버를 이용해 대규모 스토리지 시스템을 구성할 수 있다는 것이다. 기존 대용량 파일 시스템은 여러 서버와의 I/O가 일어나므로 매우 고사양이어야 했지만, HDFS의 경우에는 x86급의 서버(단, NameNode가 설치되는 서버의 경우에는 고사양이어야 한다)로 구성할 수 있다.

### HDFS의 파일 관리 정책

- HDFS는 블록 구조의 파일 시스템이다. HDFS에 저장되는 파일은 통째로 하나의 파일로 저장되는 것이 아닌, 블록 단위(일반적으로 64mb)로 나뉘어 여러 서버에 나누어 저장되게 된다.
  블록의 단위가 큰 이유는 디스크 시크 타임의 감소(일반적인 시스템은 4kb의 블록이 하드 디스크 여러 군데에 나누어 저장되어 파일 조회 시 오랜 시간이 걸리지만, 블록 크기가 크게 저장되면 이러한 문제점이 해결된다)와 NameNode가 유지하는 메타데이터의 크기 감소(HDFS에서는 모든 파일의 정보를 NameNode의 메모리에 로드하여 관리한다), 클라이언트와 네임노드의 통신 감소(블록이 많다면 네임노드가 클라이언트의 많은 수의 블록 정보를 전송해야 하지만, 블록 크기가 크다면 적은 수의 블록 정보만을 공유하면 된다) 때문이다.

- HDFS는 블록을 저장할 때 기본적으로 3개의 복제본을 저장한다. 이는 블록을 저장하는 DataNode가 장애로 다운되었을 때, 해당 파일을 읽을 수 없거나 복구할 수 없는 경우를 방지하기 위해서이다.

### NameNode와 DataNode

HDFS는 마스터-슬레이브 구조이다. 마스터는 NameNode를 의미하고, 슬레이브는 DataNode를 의미한다.

#### NameNode
NameNode는 다음과 같은 기능을 수행한다.
- 메타데이터 관리 : 파일 시스템을 유지하기 위한 메타데이터를 관리한다. 메타데이터는 빠르게 조회될 수 있도록 메모리(힙)에 유지된다.
- 데이터노드 모니터링 : 데이터노드는 네임노드에게 3초에 한번 블록 정보가 담긴 하트비트를 전송하고, 네임노드는 일정 시간동안 하트비트를 전송하지 않은 데이터 노드를 장애가 발생한 서버라고 판단하고 격리한다. 또한 데이터노드가 전송한 블록 정보를 기반으로 복제본의 수가 부족할 경우 다른 데이터노드에 블록을 복사하고, 블록 갯수가 복제본 수보다 많을 경우 데이터노드에서 블록을 제거한다.
- 클라이언트 요청 접수 : 클라이언트의 파일 관련 요청을 수신하여 결과를 전송한다.

#### DataNode
DataNode는 HDFS에 저장되는 파일들의 실제 데이터를 가지고 있는 서버이다.

- HDFS의 파일 저장 : 클라이언트가 hdfs dfs -put {로컬 파일 명} {하둡 디렉토리}와 같은 명령을 수행하면, HDFS에서는 다음과 같은 절차가 수행된다.
  - hdfs binary의 DistributedFileSystem의 create 메서드를 수행하여 네임노드와 통신하기 위한 객체인 DFSClient를 생성하고, 다시 DFSClient의 create 메서드를 호출하여 실제 네임노드와의 스트림을 생성하는 DFSOutputStream을 생성한다.
  - DFSOutputStream은 RPC통신(Protobuf)을 이용하여 네임노드의 create 메서드를 호출한다. 만일 존재하는 파일을 생성하려고 하거나 파일 시스템 용량을 초과하는 등의 오류가 발생한다면, 오류 응답이 돌아오게 된다.
  - 정상적으로 파일이 생성되었다면, 네임노드에 저장된 파일 시스템 이미지에 파일의 엔트리를 추가하고, 클라이언트에게 해당 파일을 저장할 수 있는 제어권을 부여한다.
  - 제어권을 얻은 클라이언트는 DFSOutputStream의 write 함수를 이용하여 데이터노드에 파일을 쓰기 시작한다. 이 때 전송되는 패킷의 사이즈는 64KB이다.
  - DFSOutputStream은 전송할 패킷을 내부 큐인 데이터큐에 등록한다. DFSOutputStream의 내부 스레드에서 큐에 등록된 패킷을 감지하고 NameNode의 addBlock 함수를 RPC통신으로 호출하고 이의 결과인 데이터노드 리스트를 반환받게 된다.
  - 클라이언트의 DataStreamer 객체는 데이터노드들과 연결되어 파이프 라인을 구성하고 (ex. 클라이언트의 DataStreamer-데이터노드1-데이터노드2) 패킷 전송을 시작한다. 패킷은 데이터노드 1로 전송된 뒤 데이터노드1에서 다시 데이터노드2로 전송된다.
  - 패킷을 수신한 데이터노드는 클라이언트에게 ACK 메시지를 전달하고, 클라이언트는 모든 데이터노드에게 ACK 메시지를 수신받으면 전송 큐에 존재하는 패킷을 승인 큐로 이동시킨다.
  - 승인 큐로 이동된 블록에 대한 정보를 네임노드에게 전송하여 blockReceived 메서드를 호출시킨다. 네임노드는 이 순간 해당 블록이 정상적으로 저장된 것을 인지한다.
  - 네임 노드가 정상 응답을 하면, 클라이언트는 해당 블록 정보를 승인 큐에서 제거한다. 만일 장애가 발생한다면 데이터 큐로 이동시킨 뒤 네임노드로부터 장애가 발생한 데이터 노드를 제외한 데이터노드 리스트를 수신받은 후 다시 전송을 시작한다.
  - 파일 닫기를 수행한다.

- HDFS의 파일 읽기
  - 클라이언트는 DistributedFileSystem의 open 함수를 호출하여 스트림 객체 생성을 요청한다.
  - DistributedFIleSystem 객체는 DFSClient 객체를 생성하고, DFSClient 객체는 내부의 DFSInputStream 객체를 초기화한다.
  - DataInputStream은 NameNode의 getBlockLocations 함수를 호출하여 조회 대상 파일의 블록 위치 정보를 조회한다.
  - 블록을 가진 데이터노드를 수신받은 후 가까운 위치에 존재하는 순으로 데이터노드를 정렬하고 블록을 실제로 수신하기 시작한다.
  - DFSINputStream 객체의 read 함수를 호출하여 데이터노드에게 스트림 조회를 요청한다.
  - ...
  - 스트림을 닫는다.

### Secondary NameNode
NameNode는 파일 시스템 정보를 메모리에서 관리한다. 만일 NameNode에 오류가 발생하여 서버가 재부팅 될 경우 모든 메타데이터가 유실될 수 있다.
이러한 문제점을 해결하기 위해 NameNode는 editslog와 fsimage라는 두개의 파일을 생성한다.

editslog는 HDFS의 모든 변경 이력을 저장한다. 파일 변경에 관계 된 모든 정보를 editslog에 저장한다.
fsimage는 메모리에 저장된 메타데이터의 파일 시스템 이미지를 저장한 파일이다.

NameNode가 구동될 때에 다음과 같은 방식으로 메타데이터를 로드한다.

1. 메모리에 fsimage를 로딩하여 파일 시스템 이미지를 생성
2. 메모리의 파일 시스템 이미지에 editslog에 기록된 이력을 적용
3. 메모리에 로딩된 파일 시스템 이미지를 이용해 fsimage파일을 갱신
4. editslog를 초기화

즉, fsimage는 이전 NameNode 시작 시의 최종 이미지본이고, editslog는 이전 NameNode 시작 후의 갱신된 이력이다.
만일 NameNode를 오랫동안 켜 놓아 editslog가 무한정 커진다면, 2번 과정에서 editslog를 메모리에 올릴 때 너무 큰 파일이라 올라가지 못하거나 오래 걸리는 현상이 발생한다.

이러한 문제점을 해결하기 위해 HDFS는 Secondary NameNode를 도입하게 되었다.
Secondary NameNode는 주기적으로 네임노드의 fsimage를 갱신하여 editslog가 무한정 커지는 것을 막는다.
